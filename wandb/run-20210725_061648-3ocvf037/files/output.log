[34m[1mtrain: [39m[22mScanning '/data/aza_s/SIIM/dataset/coco_format/labels/train.cache' for images and labels... 5067 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆ| 5067/5067 [00:00<?, ?it/s]
[34m[1mval: [39m[22mScanning '/data/aza_s/SIIM/dataset/coco_format/labels/valid.cache' for images and labels... 1267 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆ| 1267/1267 [00:00<?, ?it/s]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
Plotting labels...
[34m[1mautoanchor: [39m[22mEvolving anchors with Genetic Algorithm: fitness = 0.8473:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                | 256/1000 [00:00<00:00, 1278.83it/s]
[34m[1mautoanchor: [39m[22mAnalyzing anchors... anchors/target = 3.44, Best Possible Recall (BPR) = 0.7931. Attempting to improve anchors, please wait...
[34m[1mautoanchor: [39m[22mWARNING: Extremely small objects found. 1637 of 7912 labels are < 3 pixels in size.
[34m[1mautoanchor: [39m[22mRunning kmeans for 9 anchors on 6275 points...
[34m[1mautoanchor: [39m[22mthr=0.25: 0.7926 best possible recall, 6.87 anchors past thr
[34m[1mautoanchor: [39m[22mEvolving anchors with Genetic Algorithm: fitness = 0.8486: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 1302.68it/s]
Image sizes 640 train, 640 test
Using 8 dataloader workers
Logging results to runs/train/exp31
Starting training for 300 epochs...
     Epoch   gpu_mem       box       obj       cls     total   targets  img_size
  0%|                                                                                                                                                     | 0/317 [00:00<?, ?it/s]/home/ubuntu/miniconda3/envs/temp/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
[34m[1mautoanchor: [39m[22mthr=0.25: 0.7927 best possible recall, 6.84 anchors past thr
[34m[1mautoanchor: [39m[22mn=9, img_size=640, metric_all=0.447/0.673-mean/best, past_thr=0.580-mean: 69,87,  103,118,  91,181,  154,151,  109,271,  141,229,  184,262,  154,333,  211,388
[34m[1mautoanchor: [39m[22mOriginal anchors better than new anchors. Proceeding with original anchors.
torch.Size([16, 5])
     0/299     2.85G    0.1145   0.02689         0    0.1414        26       640:   3%|â–ˆâ–                                                         | 8/317 [00:03<01:03,  4.83it/s]
torch.Size([16, 5])
torch.Size([16, 5])
torch.Size([16, 5])
torch.Size([16, 5])
torch.Size([16, 5])
torch.Size([16, 5])
torch.Size([16, 5])
     0/299     2.85G    0.1101   0.02772         0    0.1378        42       640:   6%|â–ˆâ–ˆâ–ˆâ–‹                                                      | 20/317 [00:05<01:17,  3.83it/s]
Traceback (most recent call last):
  File "scripts/train.py", line 532, in <module>
    train(hyp, opt, device, tb_writer, wandb)
  File "scripts/train.py", line 294, in train
    out = model(imgs)  # forward
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "./od/models/model.py", line 76, in forward
    out = self.fpn(out)
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "./od/models/neck/FPN.py", line 73, in forward
    p41 = self.P4_1(concat1)
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "./od/models/modules/common.py", line 79, in forward
    return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=1))
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "./od/models/modules/common.py", line 45, in forward
    return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "./od/models/modules/common.py", line 29, in forward
    return self.act(self.bn(self.conv(x)))
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py", line 147, in forward
    self.num_batches_tracked = self.num_batches_tracked + 1  # type: ignore[has-type]
KeyboardInterrupt
Images sizes do not match. This will causes images to be display incorrectly in the UI.
Exception in thread Thread-13:
Traceback (most recent call last):
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py", line 28, in _pin_memory_loop
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/multiprocessing/queues.py", line 113, in get
    return _ForkingPickler.loads(res)
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/site-packages/torch/multiprocessing/reductions.py", line 289, in rebuild_storage_fd
    fd = df.detach()
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/multiprocessing/connection.py", line 492, in Client
    c = SocketClient(address)
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/multiprocessing/connection.py", line 620, in SocketClient
    s.connect(address)
FileNotFoundError: [Errno 2] No such file or directory
torch.Size([16, 5])
torch.Size([16, 5])
torch.Size([16, 5])
torch.Size([16, 5])
torch.Size([16, 5])
torch.Size([16, 5])
torch.Size([16, 5])
torch.Size([16, 5])
torch.Size([16, 5])
torch.Size([16, 5])
