[34m[1mtrain: [39m[22mScanning '/data/aza_s/SIIM/dataset/coco_format/labels/train.cache' for images and labels... 5067 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆ| 5067/5067 [00:00<?, ?it/s]
[34m[1mval: [39m[22mScanning '/data/aza_s/SIIM/dataset/coco_format/labels/valid.cache' for images and labels... 1267 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆ| 1267/1267 [00:00<?, ?it/s]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
Plotting labels...
[34m[1mautoanchor: [39m[22mEvolving anchors with Genetic Algorithm: fitness = 0.8486: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 1280.81it/s]
Image sizes 640 train, 640 test
Using 8 dataloader workers
Logging results to runs/train/exp18
Starting training for 300 epochs...
     Epoch   gpu_mem       box       obj       cls     total   targets  img_size
  0%|                                                                                                                                                     | 0/317 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "scripts/train.py", line 531, in <module>
    train(hyp, opt, device, tb_writer, wandb)
  File "scripts/train.py", line 269, in train
    for i, (imgs, targets, paths, _, img_labels) in pbar:  # batch -------------------------------------------------------------
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/site-packages/tqdm/std.py", line 1185, in __iter__
    for obj in iterable:
  File "./od/data/datasets.py", line 103, in __iter__
    yield next(self.iterator)
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1203, in _next_data
    return self._process_data(data)
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1229, in _process_data
    data.reraise()
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/site-packages/torch/_utils.py", line 425, in reraise
    raise self.exc_type(msg)
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/ubuntu/miniconda3/envs/temp/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 47, in fetch
    return self.collate_fn(data)
  File "./od/data/datasets.py", line 559, in collate_fn
    img, label, path, shapes = zip(*batch)  # transposed
ValueError: too many values to unpack (expected 4)
Images sizes do not match. This will causes images to be display incorrectly in the UI.
[34m[1mautoanchor: [39m[22mAnalyzing anchors... anchors/target = 3.44, Best Possible Recall (BPR) = 0.7931. Attempting to improve anchors, please wait...
[34m[1mautoanchor: [39m[22mWARNING: Extremely small objects found. 1637 of 7912 labels are < 3 pixels in size.
[34m[1mautoanchor: [39m[22mRunning kmeans for 9 anchors on 6275 points...
[34m[1mautoanchor: [39m[22mthr=0.25: 0.7926 best possible recall, 6.87 anchors past thr
[34m[1mautoanchor: [39m[22mn=9, img_size=640, metric_all=0.445/0.669-mean/best, past_thr=0.575-mean: 66,101,  110,128,  96,215,  157,158,  116,310,  152,259,  207,241,  168,368,  223,415
[34m[1mautoanchor: [39m[22mthr=0.25: 0.7927 best possible recall, 6.84 anchors past thr
[34m[1mautoanchor: [39m[22mn=9, img_size=640, metric_all=0.447/0.673-mean/best, past_thr=0.580-mean: 69,87,  103,118,  91,181,  154,151,  109,271,  141,229,  184,262,  154,333,  211,388
[34m[1mautoanchor: [39m[22mOriginal anchors better than new anchors. Proceeding with original anchors.